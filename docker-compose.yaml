# @format

version: '3.8'
services:
  posbackend:
    image: docker.oneshell.in/library/posbackend:local
    container_name: posbackend
    restart: always
    labels:
      - 'com.centurylinklabs.watchtower.enable=true'
    ports:
      - '8090:8090'
    depends_on:
      - mongodb
      - temporal
    environment:
      - NATS_URL=${NATS_URL}
      - NATS_REMOTE_URL=nats://178.156.139.110:4222
      - SPRING_PROFILES_ACTIVE=default
      - MONGODB_URI=${MONGODB_URI}
      - TEMPORAL_GRPC_ENDPOINT=temporal:7233
      - JAVA_OPTS=-Xms3g -Xmx3.5g -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xlog:gc*
    volumes:
      - /app/data/java/logs:/var/log/posbackend
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4096M
        reservations:
          cpus: '1'
          memory: 3072M
    networks:
      - app-network
    healthcheck:
      test:
        [
          'CMD',
          'wget',
          '--spider',
          '-q',
          'http://localhost:8090/actuator/health',
        ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  posNodeBackend:
    image: docker.oneshell.in/library/posnodebackend:latest
    container_name: posNodeBackend
    restart: always
    privileged: true
    labels:
      - 'com.centurylinklabs.watchtower.enable=true'
    ports:
      - '3001:3001'
    depends_on:
      - mongodb
    environment:
      - NODE_ENV=production
    volumes:
      - /app/data/node/logs:/var/log/posNodeBackend
    networks:
      - app-network
    healthcheck:
      test: ['CMD', 'wget', '--spider', '-q', 'http://localhost:3001/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 400M
        reservations:
          cpus: '0.2'
          memory: 100M

  posFrontend:
    image: docker.oneshell.in/library/pos:latest
    container_name: posFrontend
    restart: always
    labels:
      - 'com.centurylinklabs.watchtower.enable=true'
    ports:
      - '80:80'
    environment:
      - NODE_ENV=production
    networks:
      - app-network
    depends_on:
      - posbackend
      - posNodeBackend
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 300M
        reservations:
          cpus: '0.1'
          memory: 64M

  mongodb:
    image: mongo:latest
    container_name: mongodb
    restart: always
    volumes:
      - /app/data/mongo-data:/data/db
    labels:
      - 'com.centurylinklabs.watchtower.enable=false'
    ports:
      - '27017:27017'
    command: >
      bash -c "mongod --replSet rs0 --bind_ip_all &
      until mongosh --eval 'db.adminCommand({ ping: 1 })' >/dev/null 2>&1; do sleep 1; done;
      mongosh --quiet --eval 'const status = rs.status();
      if (status.ok === 0 || status.codeName === \"NotYetInitialized\") {
        print(\"Initializing replica set...\");
        rs.initiate();
      } else {
        print(\"Replica set already initialized.\");
      }';
      tail -f /dev/null"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1536M
        reservations:
          cpus: '0.3'
          memory: 300M
    networks:
      - app-network
    healthcheck:
      test: ['CMD', 'mongosh', '--eval', 'db.adminCommand({ping: 1})']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  nats-server:
    image: nats:2.10-alpine # ðŸš© from Docker Hub
    container_name: nats-server
    restart: always
    ports:
      - '4222:4222' # client
      - '8222:8222' # monitoring
    entrypoint: ['nats-server'] # official entrypoint anyway
    command: ['-c', '/etc/nats/nats-server.conf']
    volumes:
      - /app/data/nats-data:/data/jetstream
      - /app/data/repo/nats:/etc/nats
    environment:
      - JS_STORAGE_TYPE=file
      - JS_STORAGE_DIR=/data/jetstream
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.2'
          memory: 64M
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  watchtower:
    image: containrrr/watchtower
    container_name: watchtower
    restart: always
    labels:
      - 'com.centurylinklabs.watchtower.enable=false'
    environment:
      - TZ=Europe/London
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_ROLLING_RESTART=true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command: --interval 20
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M
    networks:
      - app-network

  PosPythonBackend:
    image: docker.oneshell.in/library/pos-python-backend:local
    container_name: PosPythonBackend
    restart: always
    labels:
      - 'com.centurylinklabs.watchtower.enable=true'
    ports:
      - '5200:5100'
    volumes:
      - /app/data:/app/data
    networks:
      - app-network
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'
    deploy:
      resources:
        limits:
          cpus: '0.4'
          memory: 400M
        reservations:
          cpus: '0.2'
          memory: 64M

  typesense:
    image: typesense/typesense:28.0
    container_name: typesense
    restart: always
    ports:
      - '8108:8108'
    volumes:
      - /app/data/typesense:/data
    environment:
      - TYPESENSE_API_KEY=1DGEyWc1JoYs6oe
      - TYPESENSE_DATA_DIR=/data
    command: '--data-dir /data --api-key 1DGEyWc1JoYs6oe --listen-port 8108 --enable-cors'
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1024M
        reservations:
          cpus: '0.2'
          memory: 512M
    networks:
      - app-network
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:8108/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    logging:
      driver: 'json-file'
      options:
        max-size: '10m'
        max-file: '3'

  temporal:
    image: temporalio/auto-setup:1.20.1
    container_name: temporal
    restart: unless-stopped
    environment:
      - DB=sqlite_default
      - SQLITE_PRAGMA_journal_mode=WAL
      - SQLITE_USER=temporal
      - SQLITE_PASSWORD=temporal
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development-sql.yaml
      - ENABLE_ES=false
      - ES_SEEDS=
      - ES_VERSION=v7
      - DEFAULT_NAMESPACE=default
      - DEFAULT_NAMESPACE_RETENTION=168h
      - SKIP_DEFAULT_NAMESPACE_CREATION=false
    ports:
      - '7233:7233'
    volumes:
      - temporal_data:/etc/temporal/config/dynamicconfig
      - /app/data/temporal:/tmp/temporal
    networks:
      - app-network
    healthcheck:
      test: ['CMD', 'tctl', '--address', 'temporal:7233', 'cluster', 'health']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  temporal-ui:
    image: temporalio/ui:2.10.3
    container_name: temporal-ui
    restart: unless-stopped
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    ports:
      - '8080:8080'
    networks:
      - app-network

volumes:
  temporal_data:
    driver: local

networks:
  app-network:
    driver: bridge
